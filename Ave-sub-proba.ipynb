{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import logging\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict probability(rf.predict_proba) for index  83  is : [[ 0.576  0.424]]\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig()\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "class_names = ['atheism', 'christian']\n",
    "\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "test_vectors = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "dict = vectorizer.vocabulary_\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(train_vectors, newsgroups_train.target)\n",
    "pred = rf.predict(test_vectors)\n",
    "\n",
    "idx = 83\n",
    "test_instance = newsgroups_test.data[idx]\n",
    "x_individual = test_vectors[idx]\n",
    "pred_proba = rf.predict_proba(test_vectors[idx])\n",
    "print(\"Predict probability(rf.predict_proba) for index \", idx,\" is :\", rf.predict_proba(test_vectors[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IndexedString(object):\n",
    "    \"\"\"String with various indexes.\"\"\"\n",
    "    def __init__(self, raw_string, split_expression=r'\\W+', bow=True):  \n",
    "        self.raw = raw_string\n",
    "        self.as_list = re.split(r'(%s)|$' % split_expression, self.raw)\n",
    "        self.as_np = np.array(self.as_list)\n",
    "        non_word = re.compile(r'(%s)|$' % split_expression).match\n",
    "        self.string_start = np.hstack(\n",
    "            ([0], np.cumsum([len(x) for x in self.as_np[:-1]])))\n",
    "        vocab = {}\n",
    "        self.inverse_vocab = []\n",
    "        self.positions = []\n",
    "        self.bow = bow\n",
    "        non_vocab = set()\n",
    "        for i, word in enumerate(self.as_np):\n",
    "            if word in non_vocab:\n",
    "                continue\n",
    "            if non_word(word):\n",
    "                non_vocab.add(word)\n",
    "                continue\n",
    "            if bow:\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = len(vocab)\n",
    "                    self.inverse_vocab.append(word)\n",
    "                    self.positions.append([])\n",
    "                idx_word = vocab[word]\n",
    "                self.positions[idx_word].append(i)\n",
    "            else:\n",
    "                self.inverse_vocab.append(word)\n",
    "                self.positions.append(i)\n",
    "        if not bow:\n",
    "            self.positions = np.array(self.positions)\n",
    "\n",
    "    def raw_string(self):\n",
    "        \"\"\"Returns the original raw string\"\"\"\n",
    "        return self.raw\n",
    "\n",
    "    def num_words(self):\n",
    "        \"\"\"Returns the number of tokens in the vocabulary for this document.\"\"\"\n",
    "        return len(self.inverse_vocab)\n",
    "\n",
    "    def word(self, id_):\n",
    "        \"\"\"Returns the word that corresponds to id_ (int)\"\"\"\n",
    "        return self.inverse_vocab[id_]\n",
    "\n",
    "    def string_position(self, id_):\n",
    "        \"\"\"Returns a np array with indices to id_ (int) ocurrences\"\"\"\n",
    "        if self.bow:\n",
    "            return self.string_start[self.positions[id_]]\n",
    "        else:\n",
    "            return self.string_start[[self.positions[id_]]]\n",
    "\n",
    "    def inverse_removing(self, words_to_remove):\n",
    "        \"\"\"Returns a string after removing the appropriate words.\n",
    "\n",
    "        If self.bow is false, replaces word with UNKWORDZ instead of removing\n",
    "        it.\n",
    "\n",
    "        Args:\n",
    "            words_to_remove: list of ids (ints) to remove\n",
    "\n",
    "        Returns:\n",
    "            original raw string with appropriate words removed.\n",
    "        \"\"\"\n",
    "        mask = np.ones(self.as_np.shape[0], dtype='bool')\n",
    "        mask[self.__get_idxs(words_to_remove)] = False\n",
    "        if not self.bow:\n",
    "            return ''.join([self.as_list[i] if mask[i]\n",
    "                            else 'UNKWORDZ' for i in range(mask.shape[0])])\n",
    "        return ''.join([self.as_list[v] for v in mask.nonzero()[0]])\n",
    "\n",
    "    def __get_idxs(self, words):\n",
    "        \"\"\"Returns indexes to appropriate words.\"\"\"\n",
    "        if self.bow:\n",
    "            return list(itertools.chain.from_iterable(\n",
    "                [self.positions[z] for z in words]))\n",
    "        else:\n",
    "            return self.positions[words]\n",
    "\n",
    "indexed_string = IndexedString(test_instance, bow = True, split_expression=r'\\W+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following part is the influence caluculation. We use the average of probability change for one class to measure the influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_intervene_point(X, cols, x0):\n",
    "    \"\"\" Randomly intervene on a set of columns of x from X. \"\"\"\n",
    "    n = X.shape[0]\n",
    "    order = np.random.permutation(range(n))\n",
    "    X_int = np.tile(x0.toarray(), (n, 1))\n",
    "    X_int[:, cols] = X.toarray()[order, cols]\n",
    "    return X_int\n",
    "\n",
    "def unary_individual_influence(dict, cls, x_ind, X):\n",
    "    y_pred_proba = pred_proba[:,0]\n",
    "    average_local_inf = {}\n",
    "    iters = 1\n",
    "\n",
    "    feature_num = len(indexed_string.inverse_vocab)\n",
    "\n",
    "    for f in range(feature_num):\n",
    "    \t#print(\"Processing feature\", f)\n",
    "        local_influence = np.zeros(y_pred_proba.shape[0])\n",
    "        vocab = indexed_string.word(f)\n",
    "        print(\"Processing word: \", vocab)\n",
    "        if dict.has_key(vocab):\n",
    "            col = dict[vocab]\n",
    "            #print(vocab)\n",
    "            for i in xrange(0,iters):\n",
    "                X_inter = random_intervene_point(X, col, x_ind)\n",
    "                y_pred_inter_proba = cls.predict_proba(X_inter)\n",
    "                local_influence = local_influence + abs(y_pred_proba - y_pred_inter_proba[:,0])*1.\n",
    "            tmp = (local_influence/iters).mean()\n",
    "            average_local_inf[vocab] = tmp\n",
    "        else:\n",
    "            average_local_inf[vocab] = 0\n",
    "            #print(tmp)\n",
    "    return average_local_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing word:  From\n",
      "Processing word:  johnchad\n",
      "Processing word:  triton\n",
      "Processing word:  unm\n",
      "Processing word:  edu\n",
      "Processing word:  jchadwic\n",
      "Processing word:  Subject\n",
      "Processing word:  Another\n",
      "Processing word:  request\n",
      "Processing word:  for\n",
      "Processing word:  Darwin\n",
      "Processing word:  Fish\n",
      "Processing word:  Organization\n",
      "Processing word:  University\n",
      "Processing word:  of\n",
      "Processing word:  New\n",
      "Processing word:  Mexico\n",
      "Processing word:  Albuquerque\n",
      "Processing word:  Lines\n",
      "Processing word:  11\n",
      "Processing word:  NNTP\n",
      "Processing word:  Posting\n",
      "Processing word:  Host\n",
      "Processing word:  Hello\n",
      "Processing word:  Gang\n",
      "Processing word:  There\n",
      "Processing word:  have\n",
      "Processing word:  been\n",
      "Processing word:  some\n",
      "Processing word:  notes\n",
      "Processing word:  recently\n",
      "Processing word:  asking\n",
      "Processing word:  where\n",
      "Processing word:  to\n",
      "Processing word:  obtain\n",
      "Processing word:  the\n",
      "Processing word:  DARWIN\n",
      "Processing word:  fish\n",
      "Processing word:  This\n",
      "Processing word:  is\n",
      "Processing word:  same\n",
      "Processing word:  question\n",
      "Processing word:  I\n",
      "Processing word:  and\n",
      "Processing word:  not\n",
      "Processing word:  seen\n",
      "Processing word:  an\n",
      "Processing word:  answer\n",
      "Processing word:  on\n",
      "Processing word:  net\n",
      "Processing word:  If\n",
      "Processing word:  anyone\n",
      "Processing word:  has\n",
      "Processing word:  a\n",
      "Processing word:  contact\n",
      "Processing word:  please\n",
      "Processing word:  post\n",
      "Processing word:  or\n",
      "Processing word:  email\n",
      "Processing word:  me\n",
      "Processing word:  Thanks\n",
      "Processing word:  john\n",
      "Processing word:  chadwick\n",
      "The five words that have the highest influence score for file  83 : \n",
      "[(u'Host', 0.12257182705718264), (u'Posting', 0.096264993026499227), (u'NNTP', 0.093941422594142246), (u'edu', 0.011350069735006914), (u'New', 0.0076624825662482635)]\n"
     ]
    }
   ],
   "source": [
    "unary_individual_inf = unary_individual_influence(dict, rf, x_individual, test_vectors)\n",
    "t = sorted(unary_individual_inf.items(), lambda x, y: cmp(x[1], y[1]), reverse=True)\n",
    "print(\"The five words that have the highest influence score for file\",idx,\": \")\n",
    "print(t[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
