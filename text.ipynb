{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text\n",
    "\n",
    "## Methods\n",
    "- LIME\n",
    "- QII\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TODO\\n1) Implement delete words over all training data set\\n2) For now only apply on binary classifier, need to modify for multi-class\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''TODO\n",
    "1) Implement delete words over all training data set\n",
    "2) For now only apply on binary classifier, need to modify for multi-class\n",
    "3) Visualization: shows the true label of shown data set\n",
    "4) Why apply influence score on test data, not train data?\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import logging\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot\n",
    "\n",
    "import itertools\n",
    "import lime\n",
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "#matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data set and train a classifier (random forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict probability(rf.predict_proba) for index  83  is : [[ 0.532  0.468]]\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig()\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "class_names = ['atheism', 'christian']\n",
    "\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "test_vectors = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "dict = vectorizer.vocabulary_\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(train_vectors, newsgroups_train.target)\n",
    "pred = rf.predict(test_vectors)\n",
    "\n",
    "c = make_pipeline(vectorizer, rf)\n",
    "idx = 83\n",
    "test_instance = newsgroups_test.data[idx]\n",
    "x_individual = test_vectors[idx]\n",
    "pred_proba = rf.predict_proba(test_vectors[idx])\n",
    "print(\"Predict probability(rf.predict_proba) for index \", idx,\" is :\", rf.predict_proba(test_vectors[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define IndexdString class and random sampling method for QII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\workshop\\Anaconda3\\lib\\re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "class IndexedString(object):\n",
    "    \"\"\"String with various indexes.\"\"\"\n",
    "    def __init__(self, raw_string, split_expression=r'\\W+', bow=True):  \n",
    "        self.raw = raw_string\n",
    "        self.as_list = re.split(r'(%s)|$' % split_expression, self.raw)\n",
    "        self.as_np = np.array(self.as_list)\n",
    "        non_word = re.compile(r'(%s)|$' % split_expression).match\n",
    "        self.string_start = np.hstack(\n",
    "            ([0], np.cumsum([len(x) for x in self.as_np[:-1]])))\n",
    "        vocab = {}\n",
    "        self.inverse_vocab = []\n",
    "        self.positions = []\n",
    "        self.bow = bow\n",
    "        non_vocab = set()\n",
    "        for i, word in enumerate(self.as_np):\n",
    "            if word in non_vocab:\n",
    "                continue\n",
    "            if non_word(word):\n",
    "                non_vocab.add(word)\n",
    "                continue\n",
    "            if bow:\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = len(vocab)\n",
    "                    self.inverse_vocab.append(word)\n",
    "                    self.positions.append([])\n",
    "                idx_word = vocab[word]\n",
    "                self.positions[idx_word].append(i)\n",
    "            else:\n",
    "                self.inverse_vocab.append(word)\n",
    "                self.positions.append(i)\n",
    "        if not bow:\n",
    "            self.positions = np.array(self.positions)\n",
    "\n",
    "    def raw_string(self):\n",
    "        \"\"\"Returns the original raw string\"\"\"\n",
    "        return self.raw\n",
    "\n",
    "    def num_words(self):\n",
    "        \"\"\"Returns the number of tokens in the vocabulary for this document.\"\"\"\n",
    "        return len(self.inverse_vocab)\n",
    "\n",
    "    def word(self, id_):\n",
    "        \"\"\"Returns the word that corresponds to id_ (int)\"\"\"\n",
    "        return self.inverse_vocab[id_]\n",
    "\n",
    "    def string_position(self, id_):\n",
    "        \"\"\"Returns a np array with indices to id_ (int) ocurrences\"\"\"\n",
    "        if self.bow:\n",
    "            return self.string_start[self.positions[id_]]\n",
    "        else:\n",
    "            return self.string_start[[self.positions[id_]]]\n",
    "\n",
    "    def inverse_removing(self, words_to_remove):\n",
    "        \"\"\"Returns a string after removing the appropriate words.\n",
    "\n",
    "        If self.bow is false, replaces word with UNKWORDZ instead of removing\n",
    "        it.\n",
    "\n",
    "        Args:\n",
    "            words_to_remove: list of ids (ints) to remove\n",
    "\n",
    "        Returns:\n",
    "            original raw string with appropriate words removed.\n",
    "        \"\"\"\n",
    "        mask = np.ones(self.as_np.shape[0], dtype='bool')\n",
    "        mask[self.__get_idxs(words_to_remove)] = False\n",
    "        if not self.bow:\n",
    "            return ''.join([self.as_list[i] if mask[i]\n",
    "                            else 'UNKWORDZ' for i in range(mask.shape[0])])\n",
    "        return ''.join([self.as_list[v] for v in mask.nonzero()[0]])\n",
    "\n",
    "    def __get_idxs(self, words):\n",
    "        \"\"\"Returns indexes to appropriate words.\"\"\"\n",
    "        if self.bow:\n",
    "            return list(itertools.chain.from_iterable(\n",
    "                [self.positions[z] for z in words]))\n",
    "        else:\n",
    "            return self.positions[words]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_intervene_point(X, cols, x0):\n",
    "    \"\"\" Randomly intervene on a set of columns of x from X. \"\"\"\n",
    "    n = X.shape[0]\n",
    "    order = np.random.permutation(range(n))\n",
    "    X_int = np.tile(x0.toarray(), (n, 1))\n",
    "    X_int[:, cols] = X.toarray()[order, cols]\n",
    "    return X_int\n",
    "\n",
    "def unary_delete_words_abs_prob(dict, cls, x_ind, X, indexed_string):\n",
    "    d = cls.predict_proba(x_ind)\n",
    "    res = {}\n",
    "    for i in range(len(indexed_string.inverse_vocab)):\n",
    "        inverse_data = []\n",
    "        inverse_data.append(indexed_string.inverse_removing([i]))\n",
    "        result = c.predict_proba(inverse_data)\n",
    "        res[indexed_string.word(i)] = abs(result[0][0]-d[0][0])\n",
    "    return res\n",
    "\n",
    "def unary_individual_influence_abs_prob(dict, cls, x_ind, X, indexed_string):\n",
    "    y_pred_proba = pred_proba[:,0]\n",
    "    average_local_inf = {}\n",
    "    iters = 1\n",
    "\n",
    "    feature_num = len(indexed_string.inverse_vocab)\n",
    "\n",
    "    for f in range(feature_num):\n",
    "        local_influence = np.zeros(y_pred_proba.shape[0])\n",
    "        vocab = indexed_string.word(f)\n",
    "        if (vocab in dict):\n",
    "            col = dict[vocab]\n",
    "            for i in range(0,iters):\n",
    "                X_inter = random_intervene_point(X, col, x_ind)\n",
    "                y_pred_inter_proba = cls.predict_proba(X_inter)\n",
    "                local_influence = local_influence + abs(y_pred_proba - y_pred_inter_proba[:,0])*1.\n",
    "            tmp = (local_influence/iters).mean()\n",
    "            average_local_inf[vocab] = tmp\n",
    "        else:\n",
    "            average_local_inf[vocab] = 0\n",
    "    return average_local_inf\n",
    "\n",
    "def unary_individual_influence_equal_prob(dict, cls, x_ind, X, indexed_string):\n",
    "    y_pred_proba = pred_proba[:,0]\n",
    "    average_local_inf = {}\n",
    "    iters = 1\n",
    "\n",
    "    feature_num = len(indexed_string.inverse_vocab)\n",
    "\n",
    "    for f in range(feature_num):\n",
    "        local_influence = np.zeros(y_pred_proba.shape[0])\n",
    "        vocab = indexed_string.word(f)\n",
    "        if (vocab in dict):\n",
    "            col = dict[vocab]\n",
    "            for i in range(0,iters):\n",
    "                X_inter = random_intervene_point(X, col, x_ind)\n",
    "                y_pred_inter_proba = cls.predict_proba(X_inter)\n",
    "                local_influence = local_influence + (y_pred_proba == y_pred_inter_proba[:,0])*1.\n",
    "            tmp = (local_influence/iters).mean()\n",
    "            average_local_inf[vocab] = tmp\n",
    "        else:\n",
    "            average_local_inf[vocab] = 0\n",
    "    return average_local_inf\n",
    "\n",
    "def unary_individual_influence_equal_label(dict, cls, x_ind, X, indexed_string):\n",
    "    y_pred_proba = pred_proba[:,0]\n",
    "    average_local_inf = {}\n",
    "    iters = 1\n",
    "\n",
    "    feature_num = len(indexed_string.inverse_vocab)\n",
    "\n",
    "    for f in range(feature_num):\n",
    "        local_influence = np.zeros(y_pred_proba.shape[0])\n",
    "        vocab = indexed_string.word(f)\n",
    "        if (vocab in dict):\n",
    "            col = dict[vocab]\n",
    "            for i in range(0,iters):\n",
    "                X_inter = random_intervene_point(X, col, x_ind)\n",
    "                y_pred_inter_proba = cls.predict_proba(X_inter)\n",
    "                if (y_pred_proba > 0.5):\n",
    "                    local_influence = local_influence + (y_pred_inter_proba[:,0] > 0.5)*1.\n",
    "                else:\n",
    "                    local_influence = local_influence + (y_pred_inter_proba[:,0])\n",
    "            tmp = (local_influence/iters).mean()\n",
    "            average_local_inf[vocab] = tmp\n",
    "        else:\n",
    "            average_local_inf[vocab] = 0\n",
    "    return average_local_inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\workshop\\Anaconda3\\lib\\re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: crackle!dabbott@munnari.oz.au (NAME)\n",
      "Subject: \"Why I am not Bertrand Russell\" (2nd request)\n",
      "Reply-To: dabbott@augean.eleceng.adelaide.edu.au (Derek Abbott)\n",
      "Organization: Electrical & Electronic Eng., University of Adelaide\n",
      "Lines: 4\n",
      "\n",
      "Could the guy who wrote the article \"Why I am not Bertrand Russell\"\n",
      "resend me a copy?\n",
      "\n",
      "Sorry, I accidently deleted my copy and forgot your name.\n",
      "\n",
      "Method delete words\n",
      "('article', 0.070000000000000007)\n",
      "('au', 0.036000000000000004)\n",
      "('guy', 0.02200000000000002)\n",
      "('wrote', 0.020000000000000018)\n",
      "('Russell', 0.014000000000000012)\n",
      "\n",
      "Method influence_abs_prob\n",
      "('article', 0.31348953974895394)\n",
      "('au', 0.30311018131101825)\n",
      "('guy', 0.29165411436541144)\n",
      "('wrote', 0.28548396094839618)\n",
      "('deleted', 0.27767642956764294)\n",
      "\n",
      "Method influence_equal_prob\n",
      "('Adelaide', 0.0)\n",
      "('request', 0.0)\n",
      "('edu', 0.0)\n",
      "('au', 0.0)\n",
      "('accidently', 0.0)\n",
      "\n",
      "Method influence_equal_label\n",
      "('Adelaide', 0.0)\n",
      "('request', 0.0)\n",
      "('edu', 0.0)\n",
      "('au', 0.0)\n",
      "('accidently', 0.0)\n",
      "\n",
      "Method LIME\n",
      "('article', -0.085291059722316112)\n",
      "('au', -0.041374047290114631)\n",
      "('guy', -0.022148858507923176)\n",
      "('wrote', -0.021463654861374887)\n",
      "('Subject', 0.012695176685518008)\n",
      "\n",
      "\n",
      "From: hudson@athena.cs.uga.edu (Paul Hudson Jr)\n",
      "Subject: Re: homosexual issues in Christianity\n",
      "Organization: University of Georgia, Athens\n",
      "Lines: 38\n",
      "\n",
      "In article <May.13.02.31.26.1993.1577@geneva.rutgers.edu> mls@panix.com (Michael Siemon) writes:\n",
      ">>I notice that the verse forbidding bestiality immediately follows the\n",
      ">>verse prohibiting what appears to be homosexual intercourse.\n",
      "\n",
      "> It is\n",
      ">absolutely irrelevant and incomparable to the issues gay Christians *do*\n",
      ">raise (which concern sexual activity within committed, consensual human\n",
      ">adult realtionships), so that your bringing it up is no more relevant\n",
      ">than the laws of kashrut.  If you cannot address the actual issues, you\n",
      ">are being bloody dishonest in trailing this red herring in front of the\n",
      ">world.\n",
      "\n",
      "No.  It is very relevant.  Homosexual acts and acts of beastiality are\n",
      "topically aranged together in the law.  This is very important.\n",
      "Anyone who would want to say that this command against homosexuality\n",
      "deals with temple prostitution (and I think you would agree that there\n",
      "is no proof for this.)  If the Law reveals the character of God, and \n",
      "is \"holy, just, and good\" as is written in the New Testament, then\n",
      "those who consider we who are against commiting homosexuals acts\n",
      "to be biggots have to address this passage of Scripture.  \n",
      "\n",
      "Why must we only discuss Scriptures that involve consensual human\n",
      "adult relationships?  Isn't that bordering on sophistry?  The point\n",
      "we are making is that God did not ordain certain kinds of sex acts.\n",
      "Not everyone who brings up these Scriptures is just trying to use and emotional\n",
      "argument that compares homosexuals to beastophiles and child molestors.\n",
      "The issue we are dealing with is that some sex acts are ungodly.  \n",
      "\n",
      "I do not have problem with a loving, nonlustful relationship with a member\n",
      "of the same sex.  I have them, and we all do.  The issue at hand is \n",
      "the sinfulness having sex with members of the same sex, or lusting after.\n",
      "So other forbidden sex acts are a valid topic for conversation. \n",
      "\n",
      "And the idea that these relationships may be  emotional  relationships\n",
      "between adult humans is red herring.  We all agree that it is okay \n",
      "for adults to  have caring relationships with one another.\n",
      "\n",
      "Link Hudson.\n",
      "\n",
      "Method delete words\n",
      "('rutgers', 0.027999999999999997)\n",
      "('God', 0.021999999999999992)\n",
      "('Christians', 0.021999999999999992)\n",
      "('acts', 0.016)\n",
      "('1993', 0.011999999999999997)\n",
      "\n",
      "Method influence_abs_prob\n",
      "('agree', 0.44169874476987459)\n",
      "('relevant', 0.43992189679218974)\n",
      "('sex', 0.43980753138075318)\n",
      "('same', 0.43917433751743379)\n",
      "('front', 0.43793305439330549)\n",
      "\n",
      "Method influence_equal_prob\n",
      "('writes', 0.0)\n",
      "('appears', 0.0)\n",
      "('And', 0.0)\n",
      "('making', 0.0)\n",
      "('Jr', 0.0)\n",
      "\n",
      "Method influence_equal_label\n",
      "('writes', 0.0)\n",
      "('appears', 0.0)\n",
      "('And', 0.0)\n",
      "('making', 0.0)\n",
      "('Jr', 0.0)\n",
      "\n",
      "Method LIME\n",
      "('rutgers', 0.030586584021093089)\n",
      "('Christians', 0.023502104598310813)\n",
      "('God', 0.020294557034289357)\n",
      "('1993', 0.018690094838491)\n",
      "('who', 0.014369674331901833)\n",
      "\n",
      "\n",
      "From: creps@lateran.ucs.indiana.edu (Stephen A. Creps)\n",
      "Subject: Re: The doctrine of Original Sin\n",
      "Organization: Indiana University\n",
      "Lines: 31\n",
      "\n",
      "In article <May.11.02.39.02.1993.28325@athos.rutgers.edu> Eugene.Bigelow@ebay.sun.com writes:\n",
      ">>This all obviously applies equally well to infants or adults, since\n",
      ">>both have souls.  Infants must be baptized, therefore, or they cannot\n",
      ">>enter into Heaven.  They too need this form of life in them, or they\n",
      ">>cannot enter into Heaven.\n",
      ">\n",
      ">Are you saying that baptism has nothing to do with asking Jesus to come into\n",
      ">your heart and accepting him as your savior, but is just a ritual that we\n",
      ">must go through to enable us to enter Heaven?\n",
      "\n",
      "   I don't think Joe was saying any such thing.  However, your question\n",
      "on \"asking Jesus to come into your heart\" seems to imply that infants\n",
      "are not allowed to have Christ in theirs.  Why must Baptism always be\n",
      "viewed by some people as a sort of \"prodigal son\" type of thing; i.e. a\n",
      "sudden change of heart, going from not accepting Christ to suddenly\n",
      "accepting Christ?  Why can't people start out with Christ from shortly\n",
      "after birth, and build their relationship from there?  After all, does\n",
      "a man suddenly meet a woman, and then marry her that same day?  From my\n",
      "experiences, I've learned that all relationships must be built,\n",
      "including one's relationship with God.\n",
      "\n",
      "   Also Joe is speaking from the standpoint that Baptism is not just a\n",
      "ritual, but that through it God bestows sacramental grace upon the\n",
      "recipient.  Certainly for those with the mental faculties to know Christ\n",
      "it is necessary to believe in Him.  However, the Sacrament itself\n",
      "bestows grace on the recipient, and makes a permanent mark of adoption\n",
      "into God's family on the soul.\n",
      "\n",
      "-\t-\t-\t-\t-\t-\t-\t-\t-\t-\n",
      "Steve Creps, Indiana University\n",
      "creps@lateran.ucs.indiana.edu\n",
      "\n",
      "Method delete words\n",
      "('rutgers', 0.034000000000000002)\n",
      "('1993', 0.025999999999999995)\n",
      "('thing', 0.018000000000000002)\n",
      "('edu', 0.014000000000000012)\n",
      "('saying', 0.012000000000000011)\n",
      "\n",
      "Method influence_abs_prob\n",
      "('thing', 0.41677824267782432)\n",
      "('saying', 0.41163737796373778)\n",
      "('edu', 0.40932775453277553)\n",
      "('built', 0.40593584379358444)\n",
      "('39', 0.40581589958158998)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "influence_name_list = ['delete words', 'influence_abs_prob', 'influence_equal_prob', 'influence_equal_label']\n",
    "influence_methods = {'delete words': unary_delete_words_abs_prob,\n",
    "             'influence_abs_prob': unary_individual_influence_abs_prob,\n",
    "             'influence_equal_prob': unary_individual_influence_equal_prob,\n",
    "             'influence_equal_label': unary_individual_influence_equal_label}\n",
    "\n",
    "for idx in range(0, 30, 5):\n",
    "    test_instance = newsgroups_test.data[idx]\n",
    "    x_individual = test_vectors[idx]\n",
    "    indexed_string = IndexedString(test_instance, bow = True, split_expression=r'\\W+')\n",
    "    print (test_instance)\n",
    "    for method in influence_name_list:\n",
    "        unary_individual_inf = influence_methods[method](dict, rf, x_individual, test_vectors, indexed_string)\n",
    "        t = sorted(unary_individual_inf.items(), key = lambda x: x[1], reverse=True)\n",
    "        print ('Method ' + method)\n",
    "        for item in t[:5]:\n",
    "            print (item)\n",
    "        print ()\n",
    "    print ('Method LIME')\n",
    "    explainer = LimeTextExplainer(class_names=class_names)\n",
    "    exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=5)\n",
    "    b = exp.as_list()\n",
    "    for _ in b:\n",
    "        print (_)\n",
    "    print (); print ()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
